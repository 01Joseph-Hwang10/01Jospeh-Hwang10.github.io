import Tags from "@site/src/components/Tag/Tags";
import values from "./values";

#### `class-validator` 데코레이터 디버깅 및 소스 코드 분석

<Tags
  metadata={["backend-agnostic", "standbylab"]}
  tags={["backend", "troubleshooting", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- 모노리포 구성으로 클라이언트와 공유가 필요한 DTO를 공통 라이브러리로 분리해 사용중인 상황.
- `class-validator`를 통해 Decorate 된 공통 라이브러리의 DTO가 NestJS의 ValidationPipe 에 의해 타입이 검증되지 않는 문제 발견.
  - `class-validator`의 작동 방식을 알기 위해 소스 코드를 들여다보는 과정에서 내부적으로 `MetadataStorage` 객체를 이용해 Typescript -> Javascript 컴파일 과정에서 데코레이터 정보를 저장하고, 모노리포 내부의 라이브러리가 각각 별도의 `class-validator` 패키지를 설치하고 있어 발생하는 문제임을 확인.
- `class-validator`를 `peerDependencies`로 추가해 모든 패키지가 하나의 `MetadataStorage` 객체를 공유하도록 함.
- => 디버깅 과정을 통해 **_모노리포 상황이나 `npm` 패키지 퍼블리싱 상황에서 패키지 간의 호환성 이슈를 고려한 공유 라이브러리 구성이 중요함_**을 배움.

:::tip

아래 링크에서 위와 관련한 더 자세한 내용을 확인할 수 있습니다.

https://01joseph-hwang10.github.io{/posts/class-validator-debugging

:::

#### 상품 정보에 대한 Caching 구현

<Tags
  metadata={["general", "backend-agnostic", "standbylab"]}
  tags={["backend", "optimization", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- 추천에 필요한 상품 정보를 Firestore에서 가져오는 과정에서 발생하는 불필요한 읽기 과정을 줄이기 위해 인메모리 캐시 도입.
- 상품 정보에 대한 캐싱 및 캐시 무효화 기능을 제공하는 NestJS 모듈 `ActionProviderModule` 구현.
- _**=> 도큐먼트 읽기 횟수 `30,000,000/일 -> 1,500,000/일`로 감소 -> 매우 큰 비용 절감 효과**_

<details>
<summary>ActionProviderService</summary>
<div markdown="1">

```ts
@Injectable()
export class ActionProviderService {
  constructor(
    @Inject(MEMORY_CACHE) private readonly cache: Cache,
    @InjectCollection(collection.mallSnapshot)
    private readonly mallSnapshot: FirestoreService<MallSnapshotSchema>,
  ) {}

  static actionsCacheKeyPrefix(mallId: string) {
    return `actions-${mallId}`;
  }

  /**
   * @description
   * Returns actions of a given `mallId`
   *
   * If the actions are already cached, it will return the cached actions.
   * If not, it will fetch the actions from Firestore and cache it.
   *
   * This method invalidates the cache if the lastSyncedAt or lastPopularityUpdatedAt
   * of the mallSnapshot is different from the cached one.
   */
  async getActions(mallSnapshot: MallSnapshot): Promise<ActionCache> {
    // Get mallId from mallSnapshot
    const mallId = mallSnapshot.mallId;

    // Get cached actions
    const actionCache = await this.cache.get<ActionCache>(
      ActionProviderService.actionsCacheKeyPrefix(mallId),
    );

    // If the lastSyncedAt or lastPopularityUpdatedAt of the mallSnapshot is different
    // from the cached one, invalidate the cache.
    // Else, return the cached actions
    if (this.cacheIsValid(actionCache, mallSnapshot)) {
      return actionCache;
    }

    // Get new actions from Firestore and build a new cache
    const actions = await mallSnapshot.actions.get();
    const newCache = {
      lastSyncedAt: mallSnapshot.lastSyncedAt,
      lastPopularityUpdatedAt: mallSnapshot.lastPopularityUpdatedAt,
      actions: actions.map((action) => action.toJSON()),
    };

    // Set new cache
    await this.cache.set(
      ActionProviderService.actionsCacheKeyPrefix(mallSnapshot.mallId),
      newCache,
    );

    // Return new cache
    return newCache;
  }

  private cacheIsValid(
    actionCache: ActionCache,
    mallSnapshot: MallSnapshot,
  ): boolean {
    return (
      actionCache &&
      actionCache.lastSyncedAt === mallSnapshot.lastSyncedAt &&
      actionCache.lastPopularityUpdatedAt ===
        mallSnapshot.lastPopularityUpdatedAt
    );
  }
}
```

</div>
</details>

##### See Also

- PickHound: https://01joseph-hwang10.github.io/docs/career-description/pickhound
- `ActionProviderService`: https://01joseph-hwang10.github.io/docs/career-description/pickhound#상품-정보에-대한-caching-구현

#### Firestore 복합 인덱스 관리를 위한 명시적 메서드 네이밍 컨벤션 수립

<Tags
  metadata={["backend-agnostic", "standbylab"]}
  tags={["backend", "improvement", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- Firestore를 도입하고 여러 필드를 기준으로 쿼리를 수행하는 경우가 늘어나면서, 복합 인덱스에 포함된 프로퍼티, 정렬 기준 등을 혼동하는 경우가 빈번히 발생.
- 모든 프로퍼티 이름을 포함하는 네이밍 컨벤션을 통해 복합 인덱스 관리를 명시적으로 하도록 함.
- => 복합 인덱스가 필요한 쿼리를 수행하는 데 발생하는 _**휴먼 에러 발생률 감소 (컨벤션 수립 전 휴먼 에러 11번 -> 수립 후 2번)**_
- => 복합 인덱스가 필요한 쿼리 구현에 필요한 시간 감소.

:::note

##### 네이밍 컨벤션 예시: `listRewardRecordByMallIdIssuanceTypeTimerange`

- list: 목록을 반환
- rewardRecord: `reward-record` 컬렉션에서
- by: 다음의 필드를 기준으로
- MallId: `mallId` 필드
- IssuanceType: `issuanceType` 필드
- Timerange: `issuedDate` 필드를 기준으로 `class Timerange` 클래스에 정의된 `startDate`, `endDate` 프로퍼티를 사용해 필터링

:::

#### 점진적인 코드베이스 이관을 통한 DB 마이그레이션

<Tags
  metadata={["backend-agnostic"]}
  tags={["backend", "improvement", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- 버져닝, JSDoc Block Tags, `backwardCompatible*` 등의 패턴을 활용한 점진적인 코드베이스 이관으로 일괄 DB 마이그레이션이 불가능한 스키마에 새로운 변경 사항을 반영

<div style={{ display: 'none '}}>
##### See Also

아래 링크에서 위와 관련한 블로그 포스트를 확인할 수 있습니다.

Insert link here

</div>

#### 상품 추천 속도 향상을 위한 로그 데이터 분석 및 코드 인스펙션

<Tags
  metadata={["general", "backend-agnostic"]}
  tags={["backend", "troubleshooting", "optimization", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- 특정 쇼핑몰에서 상품 추천 API의 응답 속도가 느린 것을 발견함.
- GCL 로그를 내려받아 `numpy`, `pandas`, `matplotlib`을 활용해 각종 지표를 살펴보았으나, 위 쇼핑몰을 제외하고는 응답 속도가 예상대로 나타남.

<details>
  <summary>당시 로그 분석에 대한 시각화 자료</summary>
  <img src="/img/projects/pickhound/metrics.jpg" />
</details>

- 이에 상품 추천 API의 코드를 인스펙션하며, `Date.now()` 를 활용해 각 단계의 응답 속도를 측정함.
- => Firestore로의 count 쿼리가 응답 지연의 원인임을 발견하고, count 쿼리를 제거해 응답 지연 문제 해결.

#### Leaky Bucket이 적용된 엔드포인트를 위한 HTTP Client 구현

<Tags
  metadata={["general", "backend-agnostic", "standbylab"]}
  tags={["feature", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- 데이터 요청이 필요한 API의 Leaky Bucket Policy로 인해 1초에 2회 수준으로 API 호출이 제한됨.
- 각 상품의 상세 정보를 하나씩 전부 요청해야 하는 상황에서 단순 API 호출로는 HTTP 429 에러 발생.
- LeakyBucketClient 클래스를 구현해 호출의 빈도를 제한하고, 429 에러 발생 시 리퀘스트 재시도.
  - HTTP 에러 코드별로 `Exception` 클래스를 만들고 `instanceof` 연산자를 활용해 에러를 구분하고 대기 시간을 조절.
- => 상품 추천에 필요한 데이터인 상품의 상세 정보를 전부 요청하는 작업을 가능케 함.

<details>
<summary>LeakyBucketClient</summary>
<div markdown="1">

```ts
interface LeakyBucketClientOptions<T> {
  mallId: string;
  requests: (() => Promise<AxiosResponse<T>>)[];
  maxLimit: number;
  leakInterval?: number;
  leakRate?: number;
  /**
   * @description
   * If timeout is set, the function will be terminated after the timeout.
   */
  timeout?: number;
}

/**
 * @description
 * This class is used to fetch data from an endpoint with leaky bucket policy.
 */
class LeakyBucketClient<T> {
  public results: T[];
  private currentAPIUsage: number;
  private timeoutExceeded: boolean;
  private state: "idle" | "running" | "finished";

  constructor(private readonly options: LeakyBucketClientOptions<T>) {
    this.currentAPIUsage = 0;
    this.timeoutExceeded = false;
    this.state = "idle";
  }

  private async getAPIUsageFromHeaders(
    headers: AxiosResponse["headers"],
  ): Promise<number> {
    const rawUsage = String(headers["x-api-call-limit"]).split("/")[0];
    const parsedUsage = Number.parseInt(rawUsage);
    return Number.isNaN(parsedUsage) ? 0 : parsedUsage;
  }

  private startTimeout() {
    const timer = setTimeout(() => {
      clearTimeout(timer);
      this.timeoutExceeded = true;
    }, this.options.timeout);
  }

  /**
   * @description
   * Compute wait time for the leak.
   *
   * @param decrementGoal The amount of decrementing the current limit.
   */
  private computWaitTime(decrementGoal: number) {
    return (decrementGoal / this.options.leakRate) * this.options.leakInterval;
  }

  /**
   * @description
   * Wait for the wait time, calculated by `computWaitTime` method.
   *
   * @param decrementGoal The amount of decrementing the current limit.
   */
  private async waitForTheLeak(decrementGoal: number) {
    // Define wait time and wait
    const waitTime = this.computWaitTime(decrementGoal);
    await wait(waitTime);

    // Decrement current limit
    this.currentAPIUsage -= decrementGoal;
  }

  /**
   * @description
   * We consider 502 and 429 errors as overflow errors.
   * While considering 502 as overflow error is not strictly correct,
   * we consider 502 as overflow error because it is highly likely that
   * 502 error is caused by the same reason as 429 error.
   */
  private async safeExecute<T>(
    request: () => Promise<AxiosResponse<T>>,
  ): Promise<LeakyBucketFetchResponse<T>> {
    try {
      const result = await request();
      this.currentAPIUsage = await this.getAPIUsageFromHeaders(result.headers);
      return {
        success: true,
        data: result.data,
        overflow: false,
        badGateway: false,
      };
    } catch (error) {
      this.currentAPIUsage = await this.getAPIUsageFromHeaders(error.headers);
      if (error instanceof TooManyRequestsException)
        return {
          success: false,
          data: null,
          overflow: true,
          badGateway: false,
        };
      if (error instanceof BadGatewayException)
        return {
          success: false,
          data: null,
          overflow: false,
          badGateway: true,
        };
      throw error;
    }
  }

  /**
   * @description
   * Execute @type {LeakyBucketClientOptions['requests']} under the leaky bucket policy.
   *
   * Note that this method is one-time use only.
   *
   * After the execution, the state of the client will be set to "finished",
   * and any further execution will throw an error.
   *
   * If any further execution is needed, create a new instance of the client.
   */
  async execute(): Promise<T[]> {
    // Check if state is idle
    if (this.state === "finished") {
      throw new Error("[LeakyBucketClient] This client has already finished.");
    }
    if (this.state === "running") {
      throw new Error("[LeakyBucketClient] This client is already running.");
    }

    // Set state to running
    this.state = "running";

    // Start timeout for preventing infinite loop
    if (this.options.timeout) this.startTimeout();

    // Request resources
    while (this.results.length < this.options.requests.length) {
      // If timeout is exceeded, throw an error
      if (this.timeoutExceeded) {
        throw new ServiceUnavailableException(
          "[LeakyBucketClient] Couldn't finish the process in time.",
        );
      }

      // Decide paginating amount based on current api limit
      const pagination = this.options.maxLimit - this.currentAPIUsage;

      // Wait for the leak for further requests
      if (pagination < 0) {
        // Set decrement goal
        const decrementGoal = Math.abs(pagination) + this.options.maxLimit;

        // Wait for bucket to be leaked
        await this.waitForTheLeak(decrementGoal);
        continue;
      }

      // Paginate promises to be sent
      const chunk = this.options.requests.slice(
        this.results.length,
        Math.min(
          this.results.length + pagination,
          this.options.requests.length + 1,
        ),
      );

      // Invoke promises
      const chunkResults = await Promise.all(
        chunk.map((each) => this.safeExecute(each)),
      );

      // Check if there's a 429 or 502 response and count
      // 429 response is counted as 1 and 502 response is counted as 5
      // (i.e. we wait 2 seconds for 429 response and 10 seconds for 502 response)
      const overflowedRequestCount = chunkResults
        .map(({ overflow, badGateway }) => (overflow ? 1 : badGateway ? 5 : 0))
        .reduce((acc, cur) => acc + cur, 0);

      // If there's a 429 response, wait for the leak interval with amount of the number of overflowed requests
      if (overflowedRequestCount > 0) {
        // Calculate remaining request and set decrement goal
        const remainingRequest = this.options.requests.slice(
          this.results.length,
        );
        const decrementGoal =
          overflowedRequestCount +
          Math.min(this.options.maxLimit, remainingRequest.length);

        // Wait for bucket to be leaked
        await this.waitForTheLeak(decrementGoal);
        continue;
      }

      // Push results to the result array
      this.results.push(...chunkResults.map(({ data }) => data));
    }

    // Set state to finished
    this.state = "finished";

    return this.results;
  }
}
```

</div>
</details>

##### See Also

- `LeakyBucketClient`: https://01joseph-hwang10.github.io/docs/career-description/pickhound#leaky-bucket이-적용된-엔드포인트를-위한-http-client-구현
- 긴 프로세스를 담당하는 Worker 인프라 구축 및 배포 자동화

#### Bandit Engine 서비스와의 연동을 위한 HTTP Client 구현

<Tags
  metadata={["backend-agnostic"]}
  tags={["feature", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- [RecommendationAPI](https://01joseph-hwang10.github.io/docs/career-description/pickhound#recommendation-api-subproject)를 [Bandit Engine](https://01joseph-hwang10.github.io/docs/career-description/pickhound#bandit-engine-subproject)과 연동하기 위해 Flask 서비스와 통신하는 HTTP Client 구현.

<details>
<summary>BanditClient</summary>
<div markdown="1">

```ts
@Injectable()
export class BanditClient {
  private endpoints: Record<string, string>;

  constructor(options: BanditClientOptions) {
    this.endpoints = {
      reward: AppURL.bandit("model", options.type, "reward"),
      getRecommendations: AppURL.bandit(
        "model",
        options.type,
        "get-recommendations",
      ),
      processProducts: AppURL.bandit(
        "model",
        options.type,
        "data_processor",
        "products_to_actions",
      ),
      updatePopularities: AppURL.bandit(
        "model",
        options.type,
        "data_processor",
        "update_popularities",
      ),
    };
  }
  /**
   * @description
   * Bandit Engine에 리퀘스트를 보낼 적의 헤더입니다.
   * 헤더에는 Bandit Engine API Key가 포함됩니다.
   */
  private defaultHeaders: RawAxiosRequestHeaders = {
    "Content-Type": "application/json",
    "X-API-KEY": process.env.BANDIT_ENGINE_API_KEY,
  };

  /**
   * @description
   * Bandit Model을 통해 추천 상품을 가져옵니다.
   *
   * @param {GetRecommendationsPayload} payload 추천 상품을 요청하기 위해 필요한 정보
   * @returns {Promise<RecommendationInfo[]>} 추천 상품 ID (`productNo`) 목록
   */
  async getRecommendedActions(
    payload: GetRecommendationsPayload,
  ): Promise<RecommendationMetadata[]> {
    const debugInfo = {
      mallId: payload.mallId,
      rootClickNo: payload.rootClickNo,
      productToIgnore: payload.productToIgnore,
      lastClickedProductNos: payload.lastClickedProductNos.join(",") || null,
      postClickNum: payload.postClickNum,
    };
    const response = await this.createRequest<
      GetRecommendationsPayload,
      GetRecommendationsResponse
    >(this.endpoints.getRecommendations, payload, debugInfo);
    return response.recommendedActions;
  }

  /**
   * @description
   * Bandit Model에 리워드를 feed 합니다.
   *
   * @param {RewardPayload} payload 리워드를 feed 하기 위해 필요한 정보
   * @returns {Promise<MallContext>} 업데이트된 쇼핑몰의 context 정보
   */
  async reward(payload: RewardPayload): Promise<MallContext> {
    const debugInfo = {
      mallId: payload.mallId,
    };
    const response = await this.createRequest<RewardPayload, RewardResponse>(
      this.endpoints.reward,
      payload,
      debugInfo,
    );
    return response.mallContext;
  }

  /**
   * @description
   * Bandit 모델을 통해 상품을 context로 변환합니다.
   *
   * 이는 추천을 요청할 때마다 상품의 context를 계산하는 것이 아니라,
   * 상품의 context를 미리 계산하여 저장해두고, 추천 요청 시에는 저장된 context를 사용하도록 하기 위함입니다.
   * 이를 통해 추천 요청 시에 상품의 context를 계산하는 시간을 줄일 수 있어, 추천 속도를 높일 수 있습니다.
   *
   * @param {ProcessProductsPayload} payload 상품을 context로 변환하기 위해 필요한 정보
   * @returns {Promise<ProcessProductsResponse>} 상품의 context 정보
   */
  async processProductsToContextVector(
    payload: ProcessProductsPayload,
  ): Promise<KeysToCamelCase<ProcessProductsResponse>> {
    const debugInfo = {
      mallId: payload.mallId,
    };
    const response = await this.createRequest<
      ProcessProductsPayload,
      ProcessProductsResponse
    >(this.endpoints.processProducts, payload, debugInfo);
    return response;
  }

  /**
   *
   * @param {UpdatePopularitiesPayload} payload 상품의 인기도를 업데이트하기 위해 필요한 정보
   * @returns
   */
  async updatePopularities(
    payload: UpdatePopularitiesPayload,
  ): Promise<ReturnType<ProductContext["toJSON"]>[]> {
    const debugInfo = {
      mallId: payload.mallId,
    };
    const response = await this.createRequest<
      UpdatePopularitiesPayload,
      UpdatePopularitiesResponse
    >(this.endpoints.updatePopularities, payload, debugInfo);
    return response.actions;
  }

  /**
   * @description
   * Bandit Engine 서버에 리퀘스트를 보내는 메소드입니다.
   *
   * @param url 요청을 보낼 HTTP URL
   * @param payload 요청의 payload
   * @param params 요청의 query string.
   *               모든 요청이 HTTP POST로 이루어지기 때문에 query string은 요청에 영향을 주지는 않습니다.
   *               GCL에서 모니터링을 위해 사용됩니다.
   * @returns
   */
  private async createRequest<P = any, R = any>(
    url: string,
    payload: P,
    params?: Record<string, string | number | boolean>,
  ): Promise<KeysToCamelCase<R>> {
    try {
      const { data } = await axios.post<R>(
        url,
        objectFromCamelToSnake(payload),
        { headers: this.defaultHeaders, params },
      );
      return objectFromSnakeToCamel(data);
    } catch (error) {
      const status: Maybe<string> = error?.response?.status;
      if (status?.toString()?.at(0) === "4") {
        throw new BadRequestException(error);
      }
      throw new BanditException(error);
    }
  }
}
```

</div>
</details>

- `snake_case`를 사용하는 Flask 서비스와 `camelCase`를 사용하는 NestJS 서비스 간의 데이터 교환을 위해 `objectFromSnakeToCamel`, `objectFromCamelToSnake` 함수를 구현.

<details>
<summary>objectFromSnakeToCamel</summary>
<div markdown="1">

```ts
export type KeysToSnakeCase<T> = T extends (infer U)[]
  ? U extends Record<string, any>
    ? KeysToCamelCase<U>[]
    : U[]
  : {
      [K in keyof T as SnakeCase<string & K>]: T[K] extends Record<string, any>
        ? KeysToSnakeCase<T[K]>
        : T[K];
    };

export const camelToSnake = (str: string): string => {
  return str.replace(/[A-Z]/g, (letter) => `_${letter.toLowerCase()}`);
};

/**
 * @description
 * Converts object's keys from camel case to snake case recursively.
 */
export const objectFromCamelToSnake = <
  T extends Record<string, any> = Record<string, any>,
>(
  obj: T,
): KeysToSnakeCase<T> => {
  return Object.keys(obj).reduce((acc, key) => {
    const value = obj[key];
    if (isPrimitive(value)) {
      acc[camelToSnake(key)] = value;
      return acc;
    }
    if (Array.isArray(value)) {
      acc[camelToSnake(key)] = value.map((item) =>
        isPrimitive(item) ? item : objectFromCamelToSnake(item),
      );
      return acc;
    }
    if (typeof value === "object") {
      acc[camelToSnake(key)] = objectFromCamelToSnake(value);
      return acc;
    }
  }, {} as any) as KeysToSnakeCase<T>;
};
```

</div>
</details>

<details>
<summary>objectFromSnakeToCamel</summary>
<div markdown="1">

```ts
export type KeysToCamelCase<T> = T extends (infer U)[]
  ? U extends Record<string, any>
    ? KeysToCamelCase<U>[]
    : U[]
  : {
      [K in keyof T as CamelCase<string & K>]: T[K] extends Record<string, any>
        ? KeysToCamelCase<T[K]>
        : T[K];
    };

export const snakeToCamel = (str: string): string => {
  return str.replace(/([-_][a-z])/g, (group) =>
    group.toUpperCase().replace("-", "").replace("_", ""),
  );
};

/**
 * @description
 * Converts object's keys from snake case to camel case recursively.
 */
export const objectFromSnakeToCamel = <
  T extends Record<string, any> = Record<string, any>,
>(
  obj: T,
): KeysToCamelCase<T> => {
  return Object.keys(obj).reduce((acc, key) => {
    const value = obj[key];
    if (isPrimitive(value)) {
      acc[snakeToCamel(key)] = value;
      return acc;
    }
    if (Array.isArray(value)) {
      acc[snakeToCamel(key)] = value.map((item) =>
        isPrimitive(item) ? item : objectFromSnakeToCamel(item),
      );
      return acc;
    }
    if (typeof value === "object") {
      acc[snakeToCamel(key)] = objectFromSnakeToCamel(value);
      return acc;
    }
  }, {} as any) as KeysToCamelCase<T>;
};
```

</div>
</details>

##### See Also

- `BanditClient`, `objectFromCamelToSnake`, `objectFromSnakeToCamel`: https://01joseph-hwang10.github.io/docs/career-description/pickhound#bandit-engine-서비스와의-연동을-위한-http-client-구현

#### 긴 프로세스를 담당하는 Worker 인프라 구축 및 배포 자동화

<Tags
  metadata={["general", "backend-agnostic", "standbylab"]}
  tags={["devops", "feature", "automation", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- 기존에는 모든 서비스를 Google Cloud Run을 이용해서 배포했음.
  - 데이터 요청이 필요한 API의 Leaky Bucket Policy로 인해, 상품 정보를 자사 Firestore DB로 가져오는 프로세스가 길어지면서 Cloud Run의 프로세스 제한 시간인 1시간을 초과하는 문제 발생.
- 프로세스 제한 시간이 없는 GCE 인스턴스 그룹과 Cloud Load Balancer를 활용한 Worker 인프라를 구축하여 이슈 해결.
  - Cloud Build Substitution Variable 과 Docker Build Args를 활용해, Cloud Run과 Worker 인프라 배포 코드 일반화.
- => Cloud Build와 Docker를 이용한 _**CI/CD 자동화로 인력 소비 최소화**_ 및 GCE Instance Group과 GCLB를 활용한 _**시스템의 유연성 확보**_.
- => 인프라 구축 과정에서 외부 API의 제약사항을 고려한 Worker 인프라 구축과정에서 실제 프로덕션 환경에서의 문제 해결 능력 향상

<details>
<summary>cloudbuild.yaml</summary>
<div markdown="1">

```yaml
# Following substitutes are required:
#
# - _PROJECT: project name (folder name among source code)
# - _DEPLOY_TO: 'GCR' | 'GCE' | 'None'
# - _SERVICE_NAME: service name (Service name used among GCP. It's the name related with Container Registry)
# - _INSTANCE_GROUP_NAME: GCE instance group name (only needed when deploy to GCE)

steps:
  # Pull the cached image
  - name: "gcr.io/cloud-builders/docker"
    entrypoint: "bash"
    args:
      - "-c"
      - "docker pull ${_IMAGE_URL}:latest || exit 0"

  # Build docker image for the project
  - name: gcr.io/cloud-builders/docker
    id: Build
    args:
      - build
      - "--build-arg"
      - "PROJECT=${_PROJECT}"
      - "--cache-from=${_IMAGE_URL}:latest"
      - "--network=cloudbuild"
      - "-t"
      - "${_IMAGE_URL}:${COMMIT_SHA}"
      - "-t"
      - "${_IMAGE_URL}:latest"
      - .
      - "-f"
      - ci/api/Dockerfile

  # Push the image
  - name: gcr.io/cloud-builders/docker
    id: Push
    args:
      - push
      - --all-tags
      - ${_IMAGE_URL}

  # Deploy the image
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk:slim"
    id: Deploy
    entrypoint: bash
    env:
      - "SERVICE_NAME=${_SERVICE_NAME}"
      - "DEPLOY_TO=${_DEPLOY_TO}"
      - "IMAGE_URL=${_IMAGE_URL}:${COMMIT_SHA}"
      - "REGION=${_DEPLOY_REGION}"
      - "PROJECT_ID=${PROJECT_ID}"
      - "INSTANCE_GROUP_NAME=${_INSTANCE_GROUP_NAME}"
    args:
      - ./ci/api/deploy.sh

images:
  - ${_IMAGE_URL}

options:
  substitutionOption: ALLOW_LOOSE

substitutions:
  _GCR_HOSTNAME: asia.gcr.io
  _IMAGE_URL: ${_GCR_HOSTNAME}/${PROJECT_ID}/${REPO_NAME}/${_SERVICE_NAME}
  _DEPLOY_REGION: asia-northeast3

tags:
  - ${_SERVICE_NAME}
```

</div>
</details>

<details>
<summary>deploy.sh</summary>
<div markdown="1">

```bash
#!/bin/bash

# Following environment variables are given:
#
# - PROJECT_ID: project id of GCP project
# - SERVICE_NAME: service name (GCR service name, only required when "DEPLOY_TO" is 'GCR')
# - DEPLOY_TO: 'GCR' | 'GCE' | 'None'
# - IMAGE_URL: image url (GCR image url)
# - REGION: region to deploy (only required when "DEPLOY_TO" is 'GCR')
# - INSTANCE_GROUP_NAME: instance group name (only required when "DEPLOY_TO" is 'GCE')

# Exit on any error
set -e

# If DEPLOY_TO is 'None', exit
if [ "$DEPLOY_TO" == "None" ]; then
  echo "Nothing to deploy"
  exit 0
fi

# If DEPLOY_TO is 'GCR', deploy to GCR
if [ "$DEPLOY_TO" == "GCR" ]; then
  echo "Deploying to GCR"
  gcloud run services update $SERVICE_NAME --platform=managed --image=$IMAGE_URL --region=$REGION --quiet
  exit 0
fi

# If DEPLOY_TO is 'GCE', deploy to GCE
if [ "$DEPLOY_TO" == "GCE" ]; then
  echo "Deploying to GCE"
  # Replace VMs
  # We replace VMs as we need to update the docker image inside the template.
  # Replacing VMs will update the docker image inside the template.
  gcloud compute instance-groups managed rolling-action replace \
    $INSTANCE_GROUP_NAME \
    --max-surge=3 \
    --max-unavailable=3 \
    --replacement-method=substitute \
    --region=$REGION
  exit 0
fi

# If DEPLOY_TO is not 'GCR' or 'GCE', exit
echo "Invalid DEPLOY_TO: $DEPLOY_TO"
exit 1
```

</div>
</details>

<details>
<summary>Dockerfile</summary>
<div markdown="1">

```dockerfile
ARG PROJECT

# Pull node image as build
FROM node:16-alpine as build
ARG PROJECT

# Set working directory
WORKDIR /app

# Copy package.json, and .npmrc
COPY package*.json ./
COPY .npmrc .

# Install dependencies
RUN npm run registry:login
RUN npm ci

# Set working directory
WORKDIR /app

# Copy source files
COPY [ "nest-cli.json", "tsconfig.json", "tsconfig.build.json", "./"]
COPY libs ./libs
COPY apps/${PROJECT} ./apps/${PROJECT}

# Build app
RUN npm run ${PROJECT}:build:prod

# Install only production dependencies
RUN npm prune --production

# Create another build stage
FROM node:16-alpine
ARG PROJECT
ENV PROJECT=${PROJECT}

# Set working directory
WORKDIR /app

# Copy from build image
COPY --from=build /app/package*.json ./
COPY --from=build /app/dist ./dist
COPY --from=build /app/node_modules ./node_modules

# Expose port
EXPOSE 3000

# Start app
CMD npm run $PROJECT:start:prod
```

</div>
</details>

##### See Also

- `cloudbuild.yaml`, `deploy.sh`, `Dockerfile`: https://01joseph-hwang10.github.io/docs/career-description/pickhound#긴-프로세스를-담당하는-worker-인프라-구축

##### Related

- [GCE instance group autoscaler 의 instance termination으로 인한 프로세스 중단 문제 해결](#gce-instance-group-autoscaler-의-instance-termination으로-인한-프로세스-중단-문제-해결)

#### GCE instance group autoscaler 의 instance termination으로 인한 프로세스 중단 문제 해결

<Tags
  metadata={["general", "backend-agnostic"]}
  tags={["backend", "devops", "troubleshooting", "@shepherd23"]}
  tagColorScheme={values.tagColorScheme}
/>

- GCE instance group autoscaler가 scale down을 하면서 instance를 종료하는 과정에서, 종료되는 instance에 할당된 프로세스를 중단하는 문제가 발생함.
- => NestJS의 `OnApplicationShutdown` 인터페이스를 구현하여 프로세스 종료 시점에 진행중인 작업을 재시작하는 로직을 구현해 이슈 해결.
  - Fire and forget 방식으로 request를 보내 Shutdown process에 영향을 주지 않도록 함.

<details>
<summary>MallSnapshotService.onApplicationShutdown</summary>
<div markdown="1">

```ts
@Injectable()
export class MallSnapshotService implements OnApplicationShutdown {
  constructor(/* Injected dependencies */) {}

  async onApplicationShutdown() {
    const cacheKeys = await this.cache.store.keys();
    const syncCacheKeys = cacheKeys.filter((key) => key.startsWith("sync-"));
    await Promise.all(syncCacheKeys.map((key) => this.cache.del(key)));
    for (const key of syncCacheKeys) {
      this.logger.log(
        `Requesting to available instance to sync the mall for ${key} before shutdown`,
      );
      const payload = { mallId: key.replace("sync-", "") };
      const headers = {
        "X-API-KEY": process.env.WORKER_API_KEY,
      };
      // Fire and forget to make sure it does not block the shutdown process
      axios.post(AppURL.worker("/feature/update/snapshot"), payload, {
        headers,
      });
    }
  }
}
```

</div>
</details>

##### See Also

- `MallSnapshotService.onApplicationShutdown`: https://01joseph-hwang10.github.io/docs/resume/backend-agnostic#gce-instance-group-autoscaler-의-instance-termination으로-인한-프로세스-중단-문제-해결
